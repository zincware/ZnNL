{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1155f508",
   "metadata": {},
   "source": [
    "# Computing Collective Variables of the NTK\n",
    "\n",
    "In this notebook we will walkthrough the computation of collective variables of the Neural Tangent Kernel (NTK) during training a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5d943",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "For calculating the NTK, we will exclusively be using the neural tangents library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02668461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import znnl as nl\n",
    "from neural_tangents import stax\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jax\n",
    "jax.default_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d379c99",
   "metadata": {},
   "source": [
    "### Data generators\n",
    "\n",
    "For the sake of covereage, we will look at the NTK properties of the Fuel data set for a small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset = dataset.dropna()\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "dataset = (dataset-dataset.mean())/dataset.std()\n",
    "\n",
    "class MPGDataGenerator(nl.data.DataGenerator):\n",
    "    \"\"\"\n",
    "    Data generator for the MPG dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Constructor for the data generator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset\n",
    "        \"\"\"        \n",
    "        train_ds = dataset.sample(frac=0.8, random_state=0)\n",
    "        train_labels = train_ds.pop(\"MPG\")\n",
    "        test_ds = dataset.drop(train_ds.index)\n",
    "        test_labels = test_ds.pop(\"MPG\")\n",
    "        \n",
    "        self.train_ds = {\"inputs\": train_ds.to_numpy(), \"targets\": train_labels.to_numpy().reshape(-1, 1)}\n",
    "        self.test_ds = {\"inputs\": test_ds.to_numpy(), \"targets\": test_labels.to_numpy().reshape(-1, 1)}\n",
    "        \n",
    "        self.data_pool = self.train_ds[\"inputs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088201ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = MPGDataGenerator(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa1b9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Networks and Models\n",
    "\n",
    "Now we can define the network architectures for which we will compute the NTK of the data.\n",
    "\n",
    "The batch size defined in the model class refers to the batching in the NTK calculation. When calculating the NTK, the number of data points used in that calculation must be an integer mutliple of the batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62250ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_network = stax.serial(\n",
    "    stax.Dense(32),\n",
    "    stax.Relu(),\n",
    "    stax.Dense(32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_model = nl.models.NTModel(\n",
    "    nt_module=dense_network,\n",
    "    optimizer=optax.adam(learning_rate=0.005),\n",
    "    input_shape=(9,),\n",
    "    batch_size=314\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9fbe0-def2-4bab-a808-8858ab2aa5e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recording \n",
    "\n",
    "Using a recorder we can track the NTK and its properties while training a model. \n",
    "Defining a recorder, we can decide which properties to track. \n",
    "We will calculate \n",
    "- Loss\n",
    "- Accuracy\n",
    "- NTK\n",
    "- Entropy of the NTK\n",
    "- Trace of the NTK\n",
    "- Frobenius norm of the Loss Derivative\n",
    "\n",
    "of the train data and the Loss and Accuracy of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acdbd1-055b-4624-accd-3f6575fc9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recorder = nl.training_recording.JaxRecorder(\n",
    "    name=\"train_recorder\",\n",
    "    loss=True,\n",
    "    ntk=True,\n",
    "    entropy= True, \n",
    "    trace=True,\n",
    "    loss_derivative=True,\n",
    "    update_rate=1\n",
    ")\n",
    "train_recorder.instantiate_recorder(\n",
    "    data_set=data_generator.train_ds\n",
    ")\n",
    "\n",
    "\n",
    "test_recorder = nl.training_recording.JaxRecorder(\n",
    "    name=\"test_recorder\",\n",
    "    loss=True,\n",
    "    update_rate=1\n",
    ")\n",
    "test_recorder.instantiate_recorder(\n",
    "    data_set=data_generator.test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612896b2-e9e2-4917-b01b-1ff56da2b142",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training strategy \n",
    "\n",
    "In order to train, we need a training strategy, which will use the defined recorders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f306c72-d3e4-4a1e-a82a-d99621c7a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_strategy = nl.training_strategies.SimpleTraining(\n",
    "    model=fuel_model, \n",
    "    loss_fn=nl.loss_functions.LPNormLoss(order=2),\n",
    "    recorders=[train_recorder, test_recorder],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bda516-9feb-4ab1-b3d3-3a552b46e28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training\n",
    "\n",
    "Now we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf2090-8265-44db-8343-caf8dfcd193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_training_metrics = training_strategy.train_model(\n",
    "    train_ds=data_generator.train_ds, \n",
    "    test_ds=data_generator.test_ds,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99646c3f-95ed-4c4e-b01e-5646b3767ff4",
   "metadata": {},
   "source": [
    "## Checking the Results\n",
    "\n",
    "Now let's use the export function of the reporter to get access to an easy to plot dataclass with all of the metrics we recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72513b0-3b57-46de-b504-65d66b4ca035",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report = train_recorder.gather_recording()\n",
    "test_report = test_recorder.gather_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3db688-241e-4cc5-8f91-685e7d0c4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_report.loss, 'o', mfc='None', label=\"Train\")\n",
    "plt.plot(test_report.loss, 'o', mfc='None', label=\"Train\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ab30b-9c4d-4b1a-95e0-ea75214a630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_report.entropy, 'o', mfc='None', label=\"Entropy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43257c-defc-4f1e-816a-ebe1ae79e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_report.trace, 'o', mfc='None', label=\"Trace\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Trace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd153b8-caa4-4095-8f9c-bcc6142d93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    train_report.loss_derivative, \n",
    "    'o', \n",
    "    mfc='None', \n",
    "    label=r\"$|| \\frac{\\partial L }{ \\partial f}||_R$\"\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss derivative norm\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
